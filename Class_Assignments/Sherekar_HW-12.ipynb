{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "za-znBfxWnW7"
   },
   "outputs": [],
   "source": [
    "# Standard libraries generally used\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns; sns.set(style=\"ticks\", color_codes=True)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import scipy.stats\n",
    "from sklearn.model_selection import RandomizedSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version= 1.12.1\n",
      "CUDA available= False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(f'PyTorch version= {torch.__version__}')\n",
    "print(f'CUDA available= {torch.cuda.is_available()}')  # CUDA optional - True when GPU present, CUDA installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IsgeGcWoFhaJ",
    "outputId": "a0793b8a-81b9-4a3e-a2fc-d1e9d61cb924"
   },
   "outputs": [],
   "source": [
    "#****************** UPLOADING RELEVANT FILES *****************\n",
    "df1 = pd.read_csv('/Users/mukulsherekar/Documents/Modeling Complex System/creditcard.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "3c0uRhjCXbAD",
    "outputId": "e8269bbd-9c9b-4091-cbdb-d0c0f8b26acb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of orginal data set is (284807, 31)\n",
      "Number of rows (data points) are: 284807\n",
      "Number of columns (features) are: 31\n",
      "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
      "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
      "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
      "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
      "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
      "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
      "\n",
      "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
      "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
      "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
      "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
      "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
      "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
      "\n",
      "        V26       V27       V28  Amount  Class  \n",
      "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
      "1  0.125895 -0.008983  0.014724    2.69      0  \n",
      "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
      "3 -0.221929  0.062723  0.061458  123.50      0  \n",
      "4  0.502292  0.219422  0.215153   69.99      0  \n",
      "\n",
      "[5 rows x 31 columns]\n",
      "Time      float64\n",
      "V1        float64\n",
      "V2        float64\n",
      "V3        float64\n",
      "V4        float64\n",
      "V5        float64\n",
      "V6        float64\n",
      "V7        float64\n",
      "V8        float64\n",
      "V9        float64\n",
      "V10       float64\n",
      "V11       float64\n",
      "V12       float64\n",
      "V13       float64\n",
      "V14       float64\n",
      "V15       float64\n",
      "V16       float64\n",
      "V17       float64\n",
      "V18       float64\n",
      "V19       float64\n",
      "V20       float64\n",
      "V21       float64\n",
      "V22       float64\n",
      "V23       float64\n",
      "V24       float64\n",
      "V25       float64\n",
      "V26       float64\n",
      "V27       float64\n",
      "V28       float64\n",
      "Amount    float64\n",
      "Class       int64\n",
      "dtype: object\n",
      "Time      False\n",
      "V1        False\n",
      "V2        False\n",
      "V3        False\n",
      "V4        False\n",
      "V5        False\n",
      "V6        False\n",
      "V7        False\n",
      "V8        False\n",
      "V9        False\n",
      "V10       False\n",
      "V11       False\n",
      "V12       False\n",
      "V13       False\n",
      "V14       False\n",
      "V15       False\n",
      "V16       False\n",
      "V17       False\n",
      "V18       False\n",
      "V19       False\n",
      "V20       False\n",
      "V21       False\n",
      "V22       False\n",
      "V23       False\n",
      "V24       False\n",
      "V25       False\n",
      "V26       False\n",
      "V27       False\n",
      "V28       False\n",
      "Amount    False\n",
      "Class     False\n",
      "dtype: bool\n",
      "#total= 284807\n",
      "#duplicated= 1081\n",
      "Time            0\n",
      "V1              0\n",
      "V2              0\n",
      "V3              0\n",
      "V4              0\n",
      "V5              0\n",
      "V6              0\n",
      "V7              0\n",
      "V8              0\n",
      "V9              0\n",
      "V10             0\n",
      "V11             0\n",
      "V12             0\n",
      "V13             0\n",
      "V14             0\n",
      "V15             0\n",
      "V16             0\n",
      "V17             0\n",
      "V18             0\n",
      "V19             0\n",
      "V20             0\n",
      "V21             0\n",
      "V22             0\n",
      "V23             0\n",
      "V24             0\n",
      "V25             0\n",
      "V26             0\n",
      "V27             0\n",
      "V28             0\n",
      "Amount          0\n",
      "Class           0\n",
      "is_duplicate    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# data check and basic properties\n",
    "df1.head()\n",
    "print(f'shape of orginal data set is {df1.shape}')\n",
    "print(f'Number of rows (data points) are: {df1.shape[0]}')\n",
    "print(f'Number of columns (features) are: {df1.shape[1]}')\n",
    "print(df1.head())\n",
    "print(df1.dtypes)\n",
    "print(df1.isnull().any())\n",
    "df1[\"is_duplicate\"]= df1.duplicated()\n",
    "print(f\"#total= {len(df1)}\")\n",
    "print(f\"#duplicated= {len(df1[df1['is_duplicate']==True])}\")\n",
    "print(df1.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "B1Rm1afuSxpl"
   },
   "outputs": [],
   "source": [
    "# replacing missing values with means\n",
    "mean_V23 = df1['V23'].mean()\n",
    "mean_V24 = df1['V24'].mean()\n",
    "mean_V25 = df1['V25'].mean()\n",
    "mean_V26 = df1['V26'].mean()\n",
    "mean_V27 = df1['V27'].mean()\n",
    "mean_V28 = df1['V28'].mean()\n",
    "\n",
    "# Impute\n",
    "df1['V23'] = df1['V23'].fillna(mean_V23)\n",
    "df1['V24'] = df1['V24'].fillna(mean_V24)\n",
    "df1['V25'] = df1['V25'].fillna(mean_V25)\n",
    "df1['V26'] = df1['V26'].fillna(mean_V26)\n",
    "df1['V27'] = df1['V27'].fillna(mean_V27)\n",
    "df1['V28'] = df1['V28'].fillna(mean_V28)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "umLL_8R4VNDj",
    "outputId": "36be66bc-7c6a-4ac0-ab9d-1d1930370577"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time            0\n",
       "V1              0\n",
       "V2              0\n",
       "V3              0\n",
       "V4              0\n",
       "V5              0\n",
       "V6              0\n",
       "V7              0\n",
       "V8              0\n",
       "V9              0\n",
       "V10             0\n",
       "V11             0\n",
       "V12             0\n",
       "V13             0\n",
       "V14             0\n",
       "V15             0\n",
       "V16             0\n",
       "V17             0\n",
       "V18             0\n",
       "V19             0\n",
       "V20             0\n",
       "V21             0\n",
       "V22             0\n",
       "V23             0\n",
       "V24             0\n",
       "V25             0\n",
       "V26             0\n",
       "V27             0\n",
       "V28             0\n",
       "Amount          0\n",
       "Class           0\n",
       "is_duplicate    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "yx7on9e-lK05"
   },
   "outputs": [],
   "source": [
    "df1 = df1.dropna(axis=0, subset=['Amount'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "YdcchfEllsSw"
   },
   "outputs": [],
   "source": [
    "df1 = df1.dropna(axis=0, subset=['Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "C5X42EM_Yn_c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00000e+00 1.00000e+00 2.00000e+00 ... 1.72787e+05 1.72788e+05\n",
      " 1.72792e+05]\n",
      "[-1.35980713  1.19185711 -1.35835406 ...  1.91956501 -0.24044005\n",
      " -0.53341252]\n",
      "[-0.07278117  0.26615071 -1.34016307 ... -0.30125385  0.53048251\n",
      " -0.18973334]\n",
      "[ 2.53634674  0.16648011  1.77320934 ... -3.24963981  0.70251023\n",
      "  0.70333737]\n",
      "[ 1.37815522  0.44815408  0.37977959 ... -0.55782812  0.68979917\n",
      " -0.50627124]\n",
      "[-0.33832077  0.06001765 -0.50319813 ...  2.63051512 -0.37796113\n",
      " -0.01254568]\n",
      "[ 0.46238778 -0.08236081  1.80049938 ...  3.0312601   0.62370772\n",
      " -0.64961669]\n",
      "[ 0.23959855 -0.07880298  0.79146096 ... -0.29682653 -0.68617999\n",
      "  1.57700625]\n",
      "[ 0.0986979   0.08510165  0.24767579 ...  0.70841718  0.67914546\n",
      " -0.41465041]\n",
      "[ 0.36378697 -0.25542513 -1.51465432 ...  0.43245405  0.39208671\n",
      "  0.48617951]\n",
      "[ 0.09079417 -0.16697441  0.20764287 ... -0.48478176 -0.39912565\n",
      " -0.91542665]\n",
      "[-0.55159953  1.61272666  0.62450146 ...  0.41161374 -1.93384882\n",
      " -1.04045834]\n",
      "[-0.61780086  1.06523531  0.06608369 ...  0.06311886 -0.96288614\n",
      " -0.03151305]\n",
      "[-0.99138985  0.48909502  0.71729273 ... -0.18369869 -1.04208166\n",
      " -0.1880929 ]\n",
      "[-0.31116935 -0.1437723  -0.16594592 ... -0.51060184  0.44962444\n",
      " -0.08431647]\n",
      "[1.46817697 0.63555809 2.34586495 ... 1.32928351 1.96256312 0.04133346]\n",
      "[-0.47040053  0.46391704 -2.89008319 ...  0.14071598 -0.60857713\n",
      " -0.30262009]\n",
      "[ 0.20797124 -0.11480466  1.10996938 ...  0.31350179  0.50992846\n",
      " -0.66037665]\n",
      "[ 0.02579058 -0.18336127 -0.12135931 ...  0.39565248  1.11398059\n",
      "  0.16742993]\n",
      "[ 0.40399296 -0.14578304 -2.2618571  ... -0.57725184  2.89784877\n",
      " -0.25611687]\n",
      "[ 0.2514121  -0.06908314  0.52497973 ...  0.00139597  0.12743352\n",
      "  0.3829481 ]\n",
      "[-0.01830678 -0.22577525  0.24799815 ...  0.23204504  0.26524492\n",
      "  0.26105733]\n",
      "[ 0.27783758 -0.63867195  0.7716794  ...  0.57822901  0.80004874\n",
      "  0.64307844]\n",
      "[-0.11047391  0.10128802  0.90941226 ... -0.03750086 -0.16329794\n",
      "  0.37677701]\n",
      "[ 0.06692807 -0.33984648 -0.68928096 ...  0.64013388  0.12320524\n",
      "  0.00879738]\n",
      "[ 0.12853936  0.1671704  -0.32764183 ...  0.26574545 -0.56915886\n",
      " -0.4736487 ]\n",
      "[-0.18911484  0.12589453 -0.13909657 ... -0.0873706   0.54666846\n",
      " -0.81826712]\n",
      "[ 0.13355838 -0.0089831  -0.05535279 ...  0.00445477  0.10882073\n",
      " -0.00241531]\n",
      "[-0.02105305  0.01472417 -0.05975184 ... -0.02656083  0.10453282\n",
      "  0.01364891]\n",
      "[149.62   2.69 378.66 ... 381.05 337.54  95.63]\n",
      "[0 1]\n",
      "[False  True]\n"
     ]
    }
   ],
   "source": [
    "# checking for unique values\n",
    "for f in list(df1.columns.values):\n",
    "    \n",
    "        print(df1[f].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zdNn180JemH2",
    "outputId": "be354104-899c-4585-8177-2215f96b01aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of fraud transactions are 492 out of 284807 i.e 0.1727485630620034%\n",
      "the number of valid transactions are 284315 out of 284807 i.e 99.82725143693798%\n"
     ]
    }
   ],
   "source": [
    "# *************************Question #2******************************************************\n",
    "# counting class labels\n",
    "labels = df1['Class'].values\n",
    "frauds = []\n",
    "for i in range(len(labels)):\n",
    "  if labels[i] == 1:\n",
    "    frauds.append(labels[i])\n",
    "\n",
    "valids = []\n",
    "for i in range(len(labels)):\n",
    "  if labels[i] == 0:\n",
    "    valids.append(labels[i])\n",
    "\n",
    "\n",
    "print(f'the number of fraud transactions are {len(frauds)} out of {len(labels)} i.e {len(frauds)/len(labels)*100}%')\n",
    "print(f'the number of valid transactions are {len(valids)} out of {len(labels)} i.e {len(valids)/len(labels)*100}%')\n",
    "\n",
    "# Since the class is higly imbalanced, AUPRC should be an evaluation metric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Hm0gUpC9f6UO"
   },
   "outputs": [],
   "source": [
    "# ******************** Question #3 ***********************************************************\n",
    "\n",
    "# Decistion Tree (DT) and Random Forest (RF) require no scaling needed because they scale invariant\n",
    "# normalization means scaling to [0,1] which is a special case of min-max scaling\n",
    "# standardization is more practical specially for optimization algorithms like gradient descent\n",
    "# for logistic regression and SVM\n",
    "# standardization means centering feature columns at mean 0 and SD=1 (imp for learing weights)\n",
    "# DT & RF = no normalization or standarzation\n",
    "# SVM and MLPC require standadization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bVRbYga4mxjB",
    "outputId": "ee947d28-b54f-4219-9975-a2240d850468"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=284807, M=31\n"
     ]
    }
   ],
   "source": [
    "# ******************************** Question #4 *************************************************************\n",
    "\n",
    "# *********************************SETTING UP X & Y ********************************************************\n",
    "\n",
    "dfX = df1.loc[:, df1.columns != 'Class']\n",
    "dfy = df1.loc[:, df1.columns == 'Class'].values.ravel()\n",
    "\n",
    "# Sanity check\n",
    "print(f'N={len(dfX)}, M={len(dfX.columns)}')\n",
    "\n",
    "\n",
    "# Set our main data structures X and y\n",
    "X = dfX.values\n",
    "y = dfy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "eI_yxtpCl59O"
   },
   "outputs": [],
   "source": [
    "# splitting 50-50 for training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.5, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "jfyAzJgOq9sS"
   },
   "outputs": [],
   "source": [
    "# 10-fold CV evaluation of a classifier\n",
    "def eval_classifier(_clf, _X, _y):\n",
    "    accuracies = []\n",
    "    kf = StratifiedKFold(n_splits=10, shuffle=False, random_state=None)\n",
    "    for train_index, test_index in kf.split(_X, _y):\n",
    "        _clf.fit(_X[train_index], _y[train_index])\n",
    "        y_pred = _clf.predict(_X[test_index])\n",
    "        #average_precision += [average_precision_score(_y[test_index], y_pred)]\n",
    "        precision, recall, thresholds = precision_recall_curve(_y[test_index], y_pred)\n",
    "        auc_precision_recall = auc(recall, precision)\n",
    "    return auc_precision_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "id": "cM03gXl-rTEX",
    "outputId": "63d7663c-b81d-479c-fa50-7a3b75130088"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUPRC of Decision Tree accuracy=0.7249798959846111\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the four classifiers wihtout pruning or regularization\n",
    "# Decision Tree\n",
    "auprc = eval_classifier(DecisionTreeClassifier(), X, y)\n",
    "print(f'AUPRC of Decision Tree accuracy={auprc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "5nvVySEorKHf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUPRC of Random Forest=0.8223097104010144\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "auprc = eval_classifier(RandomForestClassifier(), X, y)\n",
    "print(f'AUPRC of Random Forest={auprc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "JQ-6MvLp0uY9"
   },
   "outputs": [],
   "source": [
    "# standardizing dataset for SVC and MLPC usiing pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "552hHFtD2nSM",
    "outputId": "39a5f47e-244f-48db-f97f-1354b1fd2716"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUPRC of SVM=0.7700734295322329\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "pipe_svm = make_pipeline(StandardScaler(),SVC())\n",
    "                      \n",
    "pipe_svm.fit(X_train, y_train)\n",
    "y_pred = pipe_svm.predict(X_test)\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_pred)\n",
    "auprc = auc(recall, precision)\n",
    "print(f'AUPRC of SVM={auprc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ue2MDCh_6UOg",
    "outputId": "4fcceb62-a159-48dc-c3fb-526a9bd03461"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUPRC of MLPC =0.8437719410332563\n"
     ]
    }
   ],
   "source": [
    "# Neural Network\n",
    "\n",
    "pipe_nn = make_pipeline(StandardScaler(), MLPClassifier())\n",
    "                     \n",
    "pipe_nn.fit(X_train, y_train)\n",
    "y_pred = pipe_nn.predict(X_test)\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_pred)\n",
    "auprc = auc(recall, precision)\n",
    "print(f'AUPRC of MLPC ={auprc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "940Qq476m4tj",
    "outputId": "992c235a-a49b-4e8a-d9c5-2bffad8871fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUPRC of SVM with C=0.1 is 0.5378270429357478\n",
      "AUPRC of SVM with C=0.5=0.7347151969364136\n",
      "AUPRC of SVM with C=1 is 0.7700734295322329\n",
      "Best regularization parameter for SVC is 0.7700734295322329\n"
     ]
    }
   ],
   "source": [
    "# Evaluating classifiers with pruning and regularization\n",
    "\n",
    "# Checking values of C for SVM\n",
    "\n",
    "# SVM\n",
    "pipe_svm = make_pipeline(StandardScaler(),SVC(C=0.1))\n",
    "                      \n",
    "pipe_svm.fit(X_train, y_train)\n",
    "y_pred = pipe_svm.predict(X_test)\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_pred)\n",
    "auprc_low = auc(recall, precision)\n",
    "print(f'AUPRC of SVM with C=0.1 is {auprc_low}')\n",
    "\n",
    "pipe_svm = make_pipeline(StandardScaler(),SVC(C=0.5))\n",
    "                      \n",
    "pipe_svm.fit(X_train, y_train)\n",
    "y_pred = pipe_svm.predict(X_test)\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_pred)\n",
    "auprc_med = auc(recall, precision)\n",
    "print(f'AUPRC of SVM with C=0.5={auprc_med}')\n",
    "\n",
    "pipe_svm = make_pipeline(StandardScaler(),SVC(C=1))\n",
    "                      \n",
    "pipe_svm.fit(X_train, y_train)\n",
    "y_pred = pipe_svm.predict(X_test)\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_pred)\n",
    "auprc_high = auc(recall, precision)\n",
    "print(f'AUPRC of SVM with C=1 is {auprc_high}')\n",
    "print(f'Best regularization parameter for SVC is {max(auprc_low, auprc_med, auprc_high)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y_YuJUjD6SSp",
    "outputId": "6a75a7db-10ce-489c-b1ab-3e077f04bdde"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mukulsherekar/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:305: UserWarning: The total space of parameters 2 is smaller than n_iter=10. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better regularization parameter for MLPC is {'mlpclassifier__alpha': 0.1} with a score of 0.9994382140819867\n"
     ]
    }
   ],
   "source": [
    "# Grid Search for regularization parameter for Neural Network\n",
    "param_range = [0.1,1]\n",
    "np.random.seed(1)\n",
    "#param_range.rvs(10)\n",
    "\n",
    "param_grid = [{'mlpclassifier__alpha': param_range}]\n",
    "    \n",
    "rs = RandomizedSearchCV(estimator=pipe_nn, \n",
    "                  param_distributions=param_grid, \n",
    "                  scoring='accuracy', \n",
    "                  refit=True,\n",
    "                  n_iter=10,\n",
    "                  cv=10,\n",
    "                  n_jobs=-1)\n",
    "    \n",
    "rs = rs.fit(X_train, y_train)\n",
    "\n",
    "print(f'Better regularization parameter for MLPC is {rs.best_params_} with a score of {rs.best_score_}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4xwUI9ZRWXom",
    "outputId": "1a3c6052-9e11-44d0-84ce-76f3da43165f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUPRC of Decision Tree with pruning parameter 0.1 is 0.5008602528089887\n",
      "AUPRC of Decision Tree with pruning parameter 0.5 is 0.5008602528089887\n",
      "AUPRC of Decision Tree with pruning parameter 0.5 is 0.5008602528089887\n",
      "The best pruning parameter performance for Decision Tree classifier is 0.5008602528089887\n"
     ]
    }
   ],
   "source": [
    "# Pruning for Decision Tree\n",
    "auprc_low = eval_classifier(DecisionTreeClassifier(ccp_alpha=0.1), X, y)\n",
    "print(f'AUPRC of Decision Tree with pruning parameter 0.1 is {auprc_low}')\n",
    "\n",
    "auprc_med = eval_classifier(DecisionTreeClassifier(ccp_alpha=0.5), X, y)\n",
    "print(f'AUPRC of Decision Tree with pruning parameter 0.5 is {auprc_med}')\n",
    "\n",
    "auprc_high = eval_classifier(DecisionTreeClassifier(ccp_alpha=1), X, y)\n",
    "print(f'AUPRC of Decision Tree with pruning parameter 0.5 is {auprc_high}')\n",
    "\n",
    "print(f'The best pruning parameter performance for Decision Tree classifier is {max(auprc_low, auprc_med, auprc_high)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fCU5rEvKrc7L",
    "outputId": "9de95473-fc60-4fb4-a271-fb8ee8ee399b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version= 1.12.1\n",
      "CUDA available= False\n"
     ]
    }
   ],
   "source": [
    "# ************** Question: 5 & 6 PyTorch Neural Netowork ************************************\n",
    "print(f'PyTorch version= {torch.__version__}')\n",
    "print(f'CUDA available= {torch.cuda.is_available()}')  # CUDA optional - True when GPU present, CUDA installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "joO0cS6ItryD"
   },
   "outputs": [],
   "source": [
    "# setting up scaled X and y\n",
    "X_tr_sc = StandardScaler().fit_transform(X_train)\n",
    "X_ts_sc = StandardScaler().fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "yKBbYZxxroBE"
   },
   "outputs": [],
   "source": [
    "class PyTorchMLP(torch.nn.Module):  # One hidden layer\n",
    "    def __init__(self, n_hidden=10, epochs=100, eta=0.001, minibatch_size=50, seed=0):\n",
    "        super(PyTorchMLP, self).__init__()\n",
    "        self.random = np.random.RandomState(seed)  # shuffle mini batches\n",
    "        self.n_hidden = n_hidden  # size of the hidden layer\n",
    "        self.epochs = epochs  # number of iterations\n",
    "        self.eta = eta  # learning rate\n",
    "        self.minibatch_size = minibatch_size  # size of training batch - 1 would not work\n",
    "        self.optimizer = None\n",
    "        self.loss_func = torch.nn.CrossEntropyLoss()\n",
    "        self.model = None\n",
    "\n",
    "    def init_layers(self, _M:int, _K:int) -> None:\n",
    "        # data structure\n",
    "        self.model = torch.nn.Sequential(\n",
    "            torch.nn.Linear(_M, self.n_hidden),\n",
    "            torch.nn.Sigmoid(),\n",
    "            torch.nn.Linear(self.n_hidden, self.n_hidden),\n",
    "            torch.nn.Sigmoid(),\n",
    "            torch.nn.Linear(self.n_hidden, _K),\n",
    "        )\n",
    "    \n",
    "    def predict(self, _X):\n",
    "        _X = torch.FloatTensor(_X)\n",
    "        assert self.model is not None\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            y_pred = np.argmax(self.model(_X), axis=1)\n",
    "        self.model.train()\n",
    "        return y_pred.numpy()\n",
    "\n",
    "    def fit(self, _X_train, _y_train, info=False):\n",
    "        import sys\n",
    "        _X_train, _y_train = torch.FloatTensor(_X_train), torch.LongTensor(_y_train)\n",
    "        n_features= _X_train.shape[1]\n",
    "        n_output= np.unique(_y_train).shape[0]  # number of class labels\n",
    "        \n",
    "        self.init_layers(n_features, n_output)\n",
    "        self.optimizer = torch.optim.Rprop(self.model.parameters(), lr=self.eta)  # connect model to optimizer\n",
    "\n",
    "        for i in range(self.epochs):\n",
    "            indices = np.arange(_X_train.shape[0])\n",
    "            self.random.shuffle(indices)  # shuffle the data each epoch\n",
    "\n",
    "            for start_idx in range(0, indices.shape[0] - self.minibatch_size + 1, self.minibatch_size):\n",
    "                batch_idx = indices[start_idx:start_idx + self.minibatch_size]\n",
    "                self.optimizer.zero_grad()\n",
    "                \n",
    "                net_out = self.model(_X_train[batch_idx])\n",
    "                \n",
    "                loss = self.loss_func(net_out, _y_train[batch_idx])\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                if info:\n",
    "                    sys.stderr.write(f\"\\r{i+1:03d} Loss: {loss.item():6.5f}\")\n",
    "                    sys.stderr.flush()\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "GbP-eKW1tF3y"
   },
   "outputs": [],
   "source": [
    "# A derived class to have Dropout\n",
    "class MLP2(PyTorchMLP):\n",
    "    def init_layers(self, _M, _K):\n",
    "        self.model = torch.nn.Sequential(\n",
    "            torch.nn.Linear(_M, self.n_hidden),\n",
    "            torch.nn.Sigmoid(),\n",
    "            torch.nn.Dropout(0.1),\n",
    "            torch.nn.Linear(self.n_hidden, self.n_hidden),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.1),\n",
    "            torch.nn.Linear(self.n_hidden, _K),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "dMFxrsxFtHj5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUPRC using PyTorchMLP without dropout =0.796767135062383\n",
      "AUPRC using PyTorchMLP with dropout =0.7811755082670109\n"
     ]
    }
   ],
   "source": [
    "# Train \n",
    "mlp1 = PyTorchMLP(n_hidden=10, epochs=100, eta=0.001, minibatch_size=X_tr_sc.shape[0]).fit(X_tr_sc,y_train)\n",
    "mlp2 = MLP2(n_hidden=10, epochs=2000, eta=0.0001, minibatch_size=X_tr_sc.shape[0]).fit(X_tr_sc,y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_mlp1 = mlp1.predict(X_ts_sc)\n",
    "y_pred_mlp2 = mlp2.predict(X_ts_sc)\n",
    "\n",
    "precision1, recall1, thresholds1 = precision_recall_curve(y_test, y_pred_mlp1)\n",
    "auprc_mlp1 = auc(recall1, precision1)\n",
    "print(f'AUPRC using PyTorchMLP without dropout ={auprc_mlp1}')\n",
    "\n",
    "precision2, recall2, thresholds2 = precision_recall_curve(y_test, y_pred_mlp2)\n",
    "auprc_mlp2 = auc(recall2, precision2)\n",
    "print(f'AUPRC using PyTorchMLP with dropout ={auprc_mlp2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rkPLVFwC5CzJ",
    "outputId": "7d1932d3-d4c9-4f60-e977-586ddf2d7ec2"
   },
   "outputs": [],
   "source": [
    "# Question: 6 Comparison of 10-fold Cross validation of Random Forrest & two PyTorch neural networks\n",
    "\n",
    "# The AUPRC score of RF is 0.82 while those of Neural Netowrks are 0.79 and 0.78. Inspite of being more powerful\n",
    "# classifier than RF, scores are lower. This could be due to overfitting in RF or underfitting in neural netowrks.\n",
    "# Also, neural networks might need two hidden layers instead of 1. This could be due to amount of data suited for RF\n",
    "# because smaller data sets might not suit neural network and can hamper its performance.\n",
    "\n",
    "# Random Forrest is a machine learning algorithm while Neural Netowrk is a deep learning algorithm. RF is an ensemlbe\n",
    "# of Decision Tree where is tree is independent. Neural Network is a collection of layers that are interconnected\n",
    "# and cannot be separated. Maybe for this dataset, is more suited for \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hMqDvwqyvC_f",
    "outputId": "25969e61-25cb-4dcd-8ff2-fc1daf167ac7"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
